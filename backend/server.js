// ==============================
// BOSS AIX тАУ FINAL BACKEND CORE
// ==============================

import express from "express";
import cors from "cors";
import fetch from "node-fetch";

const app = express();
app.use(express.json());

app.use(cors({
  origin: "*",
  methods: ["GET", "POST"],
}));

// ЁЯФе HEALTH CHECK
app.get("/", (req, res) => {
  res.json({ ok: true, msg: "Boss AIX Backend LIVE", time: new Date() });
});

// ЁЯФе MAIN AIX REPLY ENGINE
app.post("/api/aix", async (req, res) => {
  try {
    const msg = req.body.message;
    if (!msg) return res.status(400).json({ error: "MESSAGE_REQUIRED" });

    // MODEL тЖТ llama3.2 or phi3
    const ollamaRes = await fetch("http://localhost:11434/api/generate", {
      method: "POST",
      headers: { "Content-Type": "application/json" },

      body: JSON.stringify({
        model: "llama3.2",
        prompt: `рддреВ Boss AIX рдЖрд╣реЗрд╕. рддреВ рдорд╛рдгрд╕рд╛рд╕рд╛рд░рдЦреЗ рдмреЛрд▓рд╢реАрд▓, рднрд╛рд╡рдирд╛ рдареЗрд╡рд╢реАрд▓, 
рд╕рдореЛрд░рдЪрд╛ рдХрд╛рдп рдореНрд╣рдгрддреЛ рддреЗ рд╕рдордЬрд╢реАрд▓.
рдЙрддреНрддрд░ рдиреИрд╕рд░реНрдЧрд┐рдХ, рд╕реНрдкрд╖реНрдЯ, conversational рджреЗ.
User рдореНрд╣рдгрд╛рд▓рд╛: "${msg}"`,
        stream: false,
      }),
    });

    const data = await ollamaRes.json();

    return res.json({
      boss: true,
      reply: data.response || "рдореА рддрдпрд╛рд░ рдЖрд╣реЗ.",
      model: "llama3.2",
    });

  } catch (err) {
    return res.status(500).json({ error: "AIX_INTERNAL_ERROR", details: err.message });
  }
});

app.listen(5000, () => console.log("ЁЯФе Boss AIX Backend running on 5000"));
